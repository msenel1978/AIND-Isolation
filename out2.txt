
This script evaluates the performance of the custom_score evaluation
function against a baseline agent using alpha-beta search and iterative
deepening (ID) called `AB_Improved`. The three `AB_Custom` agents use
ID and alpha-beta search with the custom_score functions defined in
game_agent.py.

                        *************************                         
                             Playing Matches                              
                        *************************                         

 Match #   Opponent    AB_Improved   AB_Custom   AB_Custom_2  AB_Custom_3 
                        Won | Lost   Won | Lost   Won | Lost   Won | Lost 
    1       Random      10  |   0    10  |   0     9  |   1     9  |   1  
    2       MM_Open     10  |   0    10  |   0     9  |   1    10  |   0  
    3      MM_Center     9  |   1     9  |   1    10  |   0     9  |   1  
    4     MM_Improved   10  |   0    10  |   0    10  |   0    10  |   0  
    5       AB_Open      4  |   6     7  |   3     6  |   4     5  |   5  
    6      AB_Center     7  |   3     7  |   3     5  |   5     5  |   5  
    7     AB_Improved    4  |   6     6  |   4     6  |   4     2  |   8  
--------------------------------------------------------------------------
           Win Rate:      77.1%        84.3%        78.6%        71.4%    

There were 8.0 timeouts during the tournament -- make sure your agent handles search timeout correctly, and consider increasing the timeout margin for your agent.


Your ID search forfeited 105.0 games while there were still legal moves available to play.

